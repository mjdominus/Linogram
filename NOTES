
20050705

Your idea about parametrized definitions, for polygons, splines,
etc., seems like a better one than you initially thought.  You don't
need a syntax as complicated as:

        define polygon {
          point v[n], c[n];
          constraints {
            c[j] = (v[j]+v[j+1])/2 for j in 1 .. n-1
            c[n] = (v[n]+v[0])/2 
          }
        }


Instead, by restricting the semantics, you can allow:

        define polygon[n] closed {
          point v[n], c[n];

          constraints {
            c[j] = (v[j] + v[j+1])/2;
          }
        }

and leave it at that.  The subscript is iterated at the time the
definition is instantiated; for example

        polygon mypoly[5];

instantiates a polygon with points v0 .. v4, c0 .. c4, and constraints

        c0 = (v0 + v1)/2;
        c1 = (v1 + v2)/2;
        c2 = (v2 + v3)/2;
        c3 = (v3 + v4)/2;
        c4 = (v4 + v0)/2;

where the subscripts in the names are all calculated mod 5.  The
mod-5-ness is effected by the "closed" keyword in the header.  If we
had instead used "open" (the default) the constraints with overflowing
subscript numbers would simply have been discarded.

Note that this works too:

        define reg_polygon[n] extends polygon[n] {
          param number r, rot = 0;
          constraints {
            v[j] = (r * cos(j * 360 / n + rot),
                    r * sin(j * 360 / n + rot));
          }
        }

It's probably better not to let the [n] be implicit in the header.
This is for two reasons.  First, you need the name to be explicitly
declared so that it is available for use in the definition, as in the
previous example.  And second, making [n] implicit would rule out

        define foo[n] extends bar[2*n+1] {
          ...
        }

which could be quite useful.

----------------------------------------------------------------

20050707

It shouldn't generate objects named 

        c0 = (v0 + v1)/2;

but rather

        c[0] = (v[0] + v[1])/2;

The draw functions can handle this just as easily, and it avoids (1)
conflicts with other items named "c1" and "v1" and (2) problems
concerning how to deal with"v[n-1]" and such.

----------------------------------------------------------------

20050705

When linogram gets builtin sin() and cos() functions, they should take
degree arguments, not radian arguments.

----------------------------------------------------------------
20050705

Syntactic additions:

        
        point p = (4,3), q = left.end;
        constraints {
          a = b = c;
        }

----------------------------------------------------------------
20050706

Note that in this definition:

        define reg_polygon[n] extends polygon[n] {
          param number r, rot = 0;
          constraints {
            v[j] = (r * cos(j * 360 / n + rot),
                    r * sin(j * 360 / n + rot));
          }
        }

r need *not* be a parameter:

        define reg_polygon[n] extends polygon[n] {
          param number rot = 0;
*         number r;
          constraints {
            v[j] = (r * cos(j * 360 / n + rot),
                    r * sin(j * 360 / n + rot));
          }
        }

which is very good, because we can do cool stuff like

        reg_polygon[5] pentagon(rot = 180, v1 = foo, v2 = bar);

and it will figure out how big the pentagon needs to be.

----------------------------------------------------------------

20050706

The parametrized definitions thing seems quite doable.  Parameters can
appear in five places:

  1. In definition headers

        DEFINE polygon[n] ... { ... }           # n is a VAR

  2. In feature declaration type names:

        polygon[3] t1, t2;                      # 3 is an EXPR

  3. In declarators:

        line edge[n];                           # n is a VAR

  4. In expressions:

        point v[n] = (v[n+1] + v[n-1]) / 2;     # n+1 and n-1 are EXPRs

  5. In drawables:

        draw { e[1]; e[2]; e[3] }               # 1,2,3 are EXPRs




        define polygon[n] closed {
          point v[n], c[n];
          line e[n];

          constraints {
            c[j] = e[j].center;   # c[j] = (v[j] + v[j+1])/2;
            e[j].start = v[j];
            e[j].end   = v[j+1];
          }
        }


Do you need some sort of explicit declaration for the iteration
variable j in this example?  Something like:

          constraints {
            forall j: c[j] = e[j].center;   # c[j] = (v[j] + v[j+1])/2;
            forall j: e[j].start = v[j];
            forall j: e[j].end   = v[j+1];
          }

You mustn't re-use n here!  Or else

        forall j: v[j].x = start.x + j/n * length;


becomes impossible, and it would be a good thing to have.

You need this on the declarations too, because otherwise how can you
say

        point v0 = start
        point v_{n-1} = end?

The natural notation is

        point v[n-1] = end;

which must not be confused with

        forall n: point v[n-1] = end

which is quite different.  On the other hand, the use of the name "n"
itself in the former declaration might be enough to disambiguate it.


----------------------------------------------------------------

20050706

Note that 

        point v[n] = (v[n+1] + v[n-1]) / 2;     # n+1 and n-1 are EXPRs

which you made up at random is silly for closed polygons, but could be
really useful for open ones.  It doesn't constrain v0 or v_n at all.

----------------------------------------------------------------

20050707

Regarding "forall", you could avoid the syntactic weirdness by just
reserving some special token to stand for the iterated variable; for
example

        forall j: v[j].x = start.x + j/n * length;

becomes

        v[_].x = start.x + _/n * length;

or some such.  Problem with this approach: it's hard to handle
doubly-parametrized types.  (You weren't planning to deal with
doubly-parametrized types anyway, but you might someday.)  A related
alternative:  multiplier variables much be capitalized, in which case
the lowercase version is automatically reserved as an iterator.  For
example

        define polygon[N] closed {
          point v[n], c[n];

          constraints {
            c[n] = (v[n] + v[n+1])/2;
          }
        }

Where N and n are implictly linked.  Then we have


        v[n].x = start.x + n/N * length;

which seems straightforward enough.


----------------------------------------------------------------
20050707

Parsing is still slow, so you can have two formats for diagram files.
The compiled version of the files can be either an ad-hoc byte-offset
format like you did for the XML syntax in the cookbook project, or
maybe just Data::Dumpering the type objects wil be sufficient.

----------------------------------------------------------------

20050707

Now, let's return to this:

  1. In definition headers

        DEFINE polygon[n] ... { ... }           # n is a VAR


This established a new multiplier parameter named "n", stored at the
top level of the type object:

        MULTIPLIER_PARAM => "n"

  2. In declarators:

        line edge[n];                           # n is a VAR

Here we check the current type to make sure that a multiplier param
has been declared with the right name ("n").   We annotate the entry
in the object hash.  Normally, it has

        edge => $LINE

but we'll adjoin additional information:

        edge => [$LINE, "n"]

or probably better, a separate hash:

        O => { edge => $LINE, ... }
        M => { edge => "n" }


  3. In feature declaration type names:

        polygon[3] t1, t2;                      # 3 is an EXPR


Here we look up the definition of "polygon" and check to make sure it
has a multiplier parameter.  If so, we record

        MULTIPLIER_VAL => 3

in the "declaration" structure.  When the type definition is complete,
we will instantiate the objects declared by the declarators.  These
themselves have

        PARAM_SPECS => ...

Just before instantiation, we install (n => 3) into the PARAM_SPECS.
We then instantiate normally.  But instantiation now has a new case.
add_subobj_declaration doesn't immediately add the subchunk; instead,
it checks for a MULTIPLIER_VAL.  If this is absent, it does the same
thing it does now.   If not, it multiplies the declaration object by
the multiplier val, effectively translating

        polygon[3] 

  4. In expressions:

        point v[n] = (v[n+1] + v[n-1]) / 2;     # n+1 and n-1 are EXPRs

  5. In drawables:

        draw { e[1]; e[2]; e[3] }               # 1,2,3 are EXPRs


----------------------------------------------------------------

20050709

What should we do if the equations are inconsistent?

Current behavior of returning immediately is dead wrong.

We could just abort, of course.

But another alternative is to try to salvage what we can.  For
example:

        P = Q;
        P.x = 1;
        P.y = 2;
        Q.y = 3;

is inconsistent, but we can still deduce P.x = Q.x = 1; only the y
parts are broken.

Here's one thing we might do.  Construct the graph G whose vertices
are variables and where u and v are connected if they appear in the
same equation.  Consider the connected components of this graph.  In
the example above, there are two connected components, one containing
the x'es and the other the y's.  You can solve the connected
components separately and discard any components that are
inconsistent, retaining the others.  This will also be faster than
solving the system as a whole.

Your original idea was that if an equation turns out to be
inconsitent, that taints all the variables in it, and all equations
with those variables become tainted, and the taint spreads, etc.; then
you discard the tainted equations.  This is equivalent to the conncted
components thing above.

In this idea, we would go:

        P.x = Q.x
        P.y = Q.y  
        P.x = 1
        P.y = 2
        Q.y = 3

        P.x = Q.x
        P.y = Q.y  
        Q.x = 1
        P.y = 2
        Q.y = 3
        
        P.x = Q.x
        P.y = Q.y  
        Q.x = 1
        Q.y = 2
        Q.y = 3

        P.x = 1
        P.y = Q.y  
        Q.x = 1
        Q.y = 2
        Q.y = 3

Then we would discover that Q.y was inconsistent.  This would taint
all the Q.y and all the P.y equations, but the others would remain:

        P.x = 1
        Q.x = 1


----------------------------------------------------------------

20050710

        require "trig";

can load trig.lino, which is simply:

        builtin sin, cos;

        __END__

        my $PI = atan2(0, -1);

        register_builtin(sin => sub { sin($_[0] * $PI / 180) });
        register_builtin(cos => sub { cos($_[0] * $PI / 180) });


20050711

Why even require the "builtin" declaration?   The only purpose it's
serving is to change the diagnotic message if you misspell a function
name.

----------------------------------------------------------------

20050711

The crucial question about parameters seems to be: when are the ASTs
converted to constraints?

Some subsidiary questions:  are parameters replaced by their values in
ASTs or in constraints?  I think the former will be easier.  Then
given

        simple S(b=4+3)

you can compile the param-spec to something like [b, [+, 4, 3]] and
then later on simply replace [VAR b] with [+, 4, 3] and then do the
evaluation as usual.

This should turn into two things in the type object: 

        O => { S => simple }

and

        V => { S.b => [+ , 4, 3] }

** When the ->draw method is called, its ASTs are converted to
constraints.  **

This is done recursively for all subobjects.

The V member is subsetted appropriately and the subset is passed as a
parameter to expression_to_constraints.

Here's the example you made up that seems to clear things up a lot:

        define simple {
          number a;
          param number b = 10;
          constraints { a*b = 20; }
        }
        define hyperb {
          simple S(b=4);
        }

When the definition of hyperb() is read, the type object constructed
for hyperb has O and V as above.  Later, when a hyperbola is drawn,
its constraints are compiled from the expression trees.  The
calculation of constraints recurses into the S object with the
environment {b=>[CON, 4]}.  Then the constraint [-, [*, [VAR, a],
[VAR, b]], 20] is processed and in the course of that the VAR[b] is
replaced with [CON 4].

----------------------------------------------------------------

20050713

OK, here's how parameter variables work.  

Every type object contains a "V" member, which is a hash.  There are
two kinds of items in V.  One is the type's own parameters, with their
default expression values.  The other is the expressions that the type
wishes to enforce on the parameter variables of its subobjects.  The
names of the latter entries have dots in them.  

At DRAW time, we do the following:

  1. Replace parameter variables in constraint expressions with their
     defining expressions or defaults.  Abort at this time if a
     parameter is unspecified.

  2. Convert expressions to equations.  

  3. Gather equations from subobjects, qualifying equations
     appropriately. 

  4. Solve equations.

There will be a Type::constraint_equations method that returns all the
type's constraint equations.  Its arguments are a (posibly empty) list
of environment hashes.  It has two phases:

  1. For each constraint expression, call Expression::substitute,
     passing the environment hashes, and also $self->{V}.  This
     removes the parameter variables from the expression; see below.
     Call expression_to_constraints on the result.

  2. For each subobject, subset $self->{V} appropriately and call
     constraint_equations recursively on the subobject, passing the
     environment hashes and the $self->{V} subset.  

Merge together the resulting sets of equations and you have the system
to be solved.

Expression::substitute is passed a list of environment hashes.  It
recurses over the expression, copying it.  When it reaches a VAR node,
it looks for the var in the environment.  There are three cases here:

  1. Var is not in the environment.  It is therefore not a parameter,
     so just leave it alone.  

  2. Var is in the environment, but all appearances of it have
     undefined value.  Raise an unspecified-parameter error.

  3. Var is in the environment with a defined value.  Take the first
     (?) such value and replace the VAR node with the result.

Question:  Does case 3 need a recursive call over the replacing value?
Your idea was "param number a=3, b=a" should be legal, but then [VAR
b] might not be properly evaluated to [CON 3].

Is "first" correct?  Or should it be "last"?

Types also need an ->is_param method, because the behavior of certain
syntactic constructions depends on that.  For example:

        sometype P(x=EXPR);

If P.x is a parameter, this adds P.x => EXPR to the current type's V
hash.  But if P.x is an ordinary variable, this adds [- P.x EXPR] to
the current type's C hash.  (Idea for later:  Always do the former,
and add constraints to the V hash whenever they have the form VAR =
EXPR, even when they're in a CONSTRAINTS section.)

Other cases:

        param sometype P;

Puts P => undef into V.

        param sometype P = EXPR;

puts P => EXPR into V.

        sometype P(x = EXPR);

puts P.x => EXPR into V or P.x = EXPR into C, as above.

Question: what does

        param sometype P(x = EXPR)

do?  Think of a plausible example.

So here's your clearing-up example again:

        define simple {
          number a;
          param number b = 10;
          constraints { a*b = 20; }
        }
        define hyperb {
          simple S(b=4);
        }

This does

        simple: { O => { a => number,
                         b => number,
                       }
                  C => { [- [* a b] 20] },
                  V => { b => 10 },
                }

        hyperb: { O => { S => simple },
                  V => { S.b => 4 },
                }

Then then we do hyperb->draw, it calls hyperb->constraints, which gets
hyperb's constraints (none) and then calls simple->constraints({b =>
4}).

simple->constraints({b => 4}) calls substitute({b => 4}, {b => 10})
on its constraint expression [- [* a b] 20], and the result is
[- [* a 4] 20].  This is then passed to expression_to_constraints,
which produces { a => 4, "" => -20 }.  hyperb->constraints qualifies
this to { S.a => 4, "" => -20 }.  This is added to the equation set.

The V hashes will have to be incorporated into the result of solving
the equations somehow. Maybe the easiest way is to have ->constraints
do it from the V hashes.  If it sees ({b=>10}, { b => 4, p.x => 12 })
it can add { b => 1, "" => -4 } to the equation set it yields up.
This won't slow down the equation solving much.  Or maybe there's a
better way to just incorporate the values from the V into the solution
hash after the equations are solved.





      